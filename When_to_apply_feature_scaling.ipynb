{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "When to apply feature scaling",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMl9JIJx/VIJakTJBqP4pkr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sasikanth1113/End-to-End-Python/blob/master/When_to_apply_feature_scaling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mquMT-tJbq9n"
      },
      "source": [
        " ### When to apply feature scaling ? \n",
        "  For suppose in any use case we will be having some features like $f_1,f_2,f_3,f_4$ \n",
        "\n",
        "Kilograms | Centimeters | Grams | Kilometers|\n",
        "---       | ---         | ---   | ---       | \n",
        "200       | 12          | 30    | 15        |\n",
        "300       | 15          | 40    | 20        |\n",
        "\n",
        "\n",
        "> Every feature have two important things **Magnitude** and **Units**.\n",
        "In the above dataset magnitude is my values and units are kilograms,centimeters,grams & Kilometers.\n",
        "\n",
        "### When should we perform feature scaling.\n",
        "Many of Machine learning algorithms are based on Euclidean (or) Manhattan distance at that time we need feature scaling.\n",
        "\n",
        "**There are four common methods to perform Feature scaling**\n",
        "\n",
        "1. **Standardisation:-** Standardisation repalces the values by z-scores\n",
        "\n",
        " <h1> <center>   $ x^1 = \\frac{x-\\bar x}{\\sigma} $ </center> </h1>\n",
        "\n",
        "This redistributes the features with their mean $\\mu$=0 and standard deviation $\\sigma$ = 1. Sklearn.preprocessing.scale helps us implementing standardisation in python.\n",
        "\n",
        "2. **Mean Normalisation:-** This distribution will have values betwen -1 and 1 with $\\mu$ = 0\n",
        "Standardisation and Mean Normalisation can be used for algorithms that assumes zero centric data like Principal component analysis (PCA).\n",
        "<h1> <center> $ x^1 = \\frac{x-mean(x)}{max(x)-min(x)}$ </center> </h1>\n",
        "\n",
        "\n",
        "3. **Min-Max Scaling:-** This scaling brings the value between 0 to 1\n",
        "<h1> <center> $x^1 = \\frac{x-min(x)}{max(x)-min(x)} $\n",
        "\n",
        "4. **Unit Vector:-** Scaling is done considering the whole feature vector to be in unit length.\n",
        "\n",
        "<h1><center> $x^1 = \\frac{x}{||x||} $ </center> </h1>\n",
        "\n",
        "> Min-Max scaling and unit vector technique produces values of range [0,1].  \n",
        "> When dealing with features with hard boundaries this is quite useful. For example when dealing with Image data, the colors can range only from 0 to 255.\n",
        "\n",
        "### Examples of algorthim where Feature scaling matters\n",
        "\n",
        "1. K-means uses Euclidean distance measure here scaling matters\n",
        "2. KNN also require feature scaling.\n",
        "3. PCA tries to get the feature with maximum variance here too feature scaling is important\n",
        "4. Gradient descent calculation speed increases as $\\theta$ calcualtion becomes faster after feature scaling.(E.g Linear regression).\n",
        "\n",
        "**Note:- Naive bayes, Linear Discriminant Analysis & Tree-based models are not affected by feature scaling.In short any algorithm which is not Distance based is not affected by feature scaling.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egjDDiNJdkWe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}